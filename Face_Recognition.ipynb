{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5ebeb722-dcec-4427-aead-101d9d6f9d12",
      "metadata": {
        "id": "5ebeb722-dcec-4427-aead-101d9d6f9d12"
      },
      "source": [
        "# Dependencies\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1d117108",
      "metadata": {},
      "source": [
        "##### The model was trained on google colab, but most of the stuff was run locally. The unzipping part is only necessary if you run on colab. You'll also need to capture the images locally and upload them to be able to train with a colab GPU. I tried connecting colab to my local runtime to make it simpler, didn't work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tOGh5s_bGIo0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOGh5s_bGIo0",
        "outputId": "969db075-e76f-4f22-93cd-94e166a5df2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XHCq8U1mGa_R",
      "metadata": {
        "id": "XHCq8U1mGa_R"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Opens the zip file in read mode\n",
        "zip_ref = zipfile.ZipFile('drive/MyDrive/data.zip', 'r')\n",
        "zip_ref.extractall()  # Extracts the files\n",
        "zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "890d5155-5ace-47b1-92e5-f4706c045650",
      "metadata": {
        "id": "890d5155-5ace-47b1-92e5-f4706c045650"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23b5d083-6452-4f7a-88a1-70f950f3ef40",
      "metadata": {
        "id": "23b5d083-6452-4f7a-88a1-70f950f3ef40"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f3aba9a7-f30c-4725-866d-e4e80b179425",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3aba9a7-f30c-4725-866d-e4e80b179425",
        "outputId": "9c1b93c6-1b72-4ccc-f4c0-8dda6ac4e49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 183] Cannot create a file when that file already exists: 'data\\\\anchor'\n",
            "[WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'\n",
            "[WinError 183] Cannot create a file when that file already exists: 'data\\\\negative'\n"
          ]
        }
      ],
      "source": [
        "# Setting up folders unless they already exist: anchor, positive, negative\n",
        "ANC_PATH = os.path.join('data', 'anchor')\n",
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "\n",
        "for path in [ANC_PATH, POS_PATH, NEG_PATH]:\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except Exception as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0b5c7fd0-4643-463e-b17a-7094f47529de",
      "metadata": {
        "id": "0b5c7fd0-4643-463e-b17a-7094f47529de"
      },
      "source": [
        "# Collecting data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdf0de1-dafd-46a7-a10e-40eb4f72aead",
      "metadata": {
        "id": "6fdf0de1-dafd-46a7-a10e-40eb4f72aead",
        "outputId": "99120b1b-ecbb-47ef-8e16-c06febe124ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tar: Must specify one of -c, -r, -t, -u, -x\n"
          ]
        }
      ],
      "source": [
        "!tar - xf lfw.tgz  # http://vis-www.cs.umass.edu/lfw/#download for negative images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4160e5d3-6a3b-4ed9-8267-1c82645cd04f",
      "metadata": {
        "id": "4160e5d3-6a3b-4ed9-8267-1c82645cd04f"
      },
      "outputs": [],
      "source": [
        "for directory in os.listdir('lfw'):\n",
        "    for file in os.listdir(os.path.join('lfw', directory)):\n",
        "        EX_PATH = os.path.join('lfw', directory, file)\n",
        "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
        "        os.replace(EX_PATH, NEW_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "91a4699c-b0ec-4c15-bd6f-72f8187a2edd",
      "metadata": {
        "id": "91a4699c-b0ec-4c15-bd6f-72f8187a2edd"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Same size as downloaded images\n",
        "    frame = frame[120:120+250, 200:200+250, :]\n",
        "    cv2.imshow('Image Collection', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "        path_name = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        cv2.imwrite(path_name, frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "        path_name = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        cv2.imwrite(path_name, frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5d916ae8-5e83-4df2-8c23-25c5c5718276",
      "metadata": {
        "id": "5d916ae8-5e83-4df2-8c23-25c5c5718276"
      },
      "source": [
        "# Loading an preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ee0fc5ad-b5dd-44c3-a356-a14e2ddc11e7",
      "metadata": {
        "id": "ee0fc5ad-b5dd-44c3-a356-a14e2ddc11e7"
      },
      "outputs": [],
      "source": [
        "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(300)\n",
        "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(300)\n",
        "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f829459c",
      "metadata": {
        "id": "f829459c"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path):\n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    img = tf.image.resize(img, (100, 100))\n",
        "    img = img/255.0\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2a1d6e52",
      "metadata": {
        "id": "2a1d6e52"
      },
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip(\n",
        "    (anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip(\n",
        "    (anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0c97a507",
      "metadata": {
        "id": "0c97a507"
      },
      "outputs": [],
      "source": [
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return (preprocess(input_img), preprocess(validation_img), label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3264d9cf",
      "metadata": {
        "id": "3264d9cf"
      },
      "outputs": [],
      "source": [
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1024)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "81c4e4be",
      "metadata": {
        "id": "81c4e4be"
      },
      "outputs": [],
      "source": [
        "train_data = data.take(round(len(data)*0.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)\n",
        "\n",
        "test_data = data.skip(round(len(data)*0.7))\n",
        "test_data = test_data.take(round(len(data)*0.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c1670f1c",
      "metadata": {
        "id": "c1670f1c"
      },
      "source": [
        "# Building the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2dece0eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dece0eb",
        "outputId": "7651711b-894c-4da0-90ba-e9a6e06f8087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_img (InputLayer)      [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              37752832  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,960,448\n",
            "Trainable params: 38,960,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def make_embedding():\n",
        "    inp = Input(shape=(100, 100, 3), name='input_img')\n",
        "\n",
        "    conv1 = Conv2D(64, (10, 10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2, 2), padding='same')(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (7, 7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2, 2), padding='same')(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (4, 4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2, 2), padding='same')(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (4, 4), activation='relu')(m3)\n",
        "    f1 = Flatten()(conv4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "\n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')\n",
        "\n",
        "\n",
        "embedding = make_embedding()\n",
        "\n",
        "embedding.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1e27399c",
      "metadata": {
        "id": "1e27399c"
      },
      "outputs": [],
      "source": [
        "class L1Dist(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding-validation_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e3810c1",
      "metadata": {
        "id": "8e3810c1"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    input_image = Input(name='input_img', shape=(100, 100, 3))\n",
        "    validation_image = Input(name='validation_img', shape=(100, 100, 3))\n",
        "\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image),\n",
        "                              embedding(validation_image))\n",
        "\n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "\n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
        "\n",
        "\n",
        "siamese_model = make_model()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "66a0224b",
      "metadata": {
        "id": "66a0224b"
      },
      "source": [
        "# Training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7f0562d4",
      "metadata": {
        "id": "7f0562d4"
      },
      "outputs": [],
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "20f4292f",
      "metadata": {
        "id": "20f4292f"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.optimizers.Adam(1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b695a4ac",
      "metadata": {
        "id": "b695a4ac"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=optimizer, siamese_model=siamese_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "50abcb2e",
      "metadata": {
        "id": "50abcb2e"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        x = batch[:2]\n",
        "        y = batch[2]\n",
        "\n",
        "        yhat = siamese_model(x, training=True)\n",
        "\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "\n",
        "    print(loss)\n",
        "\n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ff469adc",
      "metadata": {
        "id": "ff469adc"
      },
      "outputs": [],
      "source": [
        "def train(data, EPOCHS):\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "        for idx, batch in enumerate(data):\n",
        "            train_step(batch)\n",
        "            progbar.update(idx+1)\n",
        "\n",
        "        if epoch % 10 == 10:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a84a76b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a84a76b5",
        "outputId": "24c1b977-9bf8-41dc-d273-260f0d0a3c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1/50\n",
            "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "26/27 [===========================>..] - ETA: 0sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "27/27 [==============================] - 19s 207ms/step\n",
            "\n",
            " Epoch 2/50\n",
            "27/27 [==============================] - 5s 187ms/step\n",
            "\n",
            " Epoch 3/50\n",
            "27/27 [==============================] - 5s 191ms/step\n",
            "\n",
            " Epoch 4/50\n",
            "27/27 [==============================] - 5s 190ms/step\n",
            "\n",
            " Epoch 5/50\n",
            "27/27 [==============================] - 5s 192ms/step\n",
            "\n",
            " Epoch 6/50\n",
            "27/27 [==============================] - 5s 190ms/step\n",
            "\n",
            " Epoch 7/50\n",
            "27/27 [==============================] - 5s 186ms/step\n",
            "\n",
            " Epoch 8/50\n",
            "27/27 [==============================] - 5s 185ms/step\n",
            "\n",
            " Epoch 9/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "\n",
            " Epoch 10/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 11/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 12/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 13/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 14/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 15/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 16/50\n",
            "27/27 [==============================] - 5s 179ms/step\n",
            "\n",
            " Epoch 17/50\n",
            "27/27 [==============================] - 5s 180ms/step\n",
            "\n",
            " Epoch 18/50\n",
            "27/27 [==============================] - 5s 180ms/step\n",
            "\n",
            " Epoch 19/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 20/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 21/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 22/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "\n",
            " Epoch 23/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 24/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "\n",
            " Epoch 25/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 26/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "\n",
            " Epoch 27/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 28/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 29/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 30/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 31/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 32/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 33/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 34/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 35/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 36/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 37/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 38/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 39/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 40/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 41/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 42/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 43/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 44/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 45/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 46/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 47/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 48/50\n",
            "27/27 [==============================] - 5s 181ms/step\n",
            "\n",
            " Epoch 49/50\n",
            "27/27 [==============================] - 5s 182ms/step\n",
            "\n",
            " Epoch 50/50\n",
            "27/27 [==============================] - 5s 183ms/step\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "train(train_data, EPOCHS)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0BKO1aPDehxy",
      "metadata": {
        "id": "0BKO1aPDehxy"
      },
      "source": [
        "# Evaluating and saving\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "OXSGJzBaIJxC",
      "metadata": {
        "id": "OXSGJzBaIJxC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "Unv1P-DrqHnC",
      "metadata": {
        "id": "Unv1P-DrqHnC"
      },
      "outputs": [],
      "source": [
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "D0-QVcQEqRVo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0-QVcQEqRVo",
        "outputId": "482ecaae-a347-4d9f-9b8d-ddc7aa124658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "y_hat = siamese_model.predict([test_input, test_val])\n",
        "pred_labels = [1 if prediction > 0.5 else 0 for prediction in y_hat]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "n1tDtnMiqS-d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1tDtnMiqS-d",
        "outputId": "b4ac49c1-4086-4992-efe4-cbaf93314f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
            "[1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(pred_labels)\n",
        "print(y_true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7Li_yW4gqzTc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Li_yW4gqzTc",
        "outputId": "030d05e7-0b6f-46c8-c91c-f62ddab12096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = Recall()\n",
        "m.update_state(y_true, y_hat)\n",
        "m.result().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5_YNWer_q6oC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_YNWer_q6oC",
        "outputId": "700de636-caf3-4190-8a26-9945aa933295"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = Precision()\n",
        "m.update_state(y_true, y_hat)\n",
        "m.result().numpy()\n",
        "plt.subplot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "TOexwRLasIQ_",
      "metadata": {
        "id": "TOexwRLasIQ_"
      },
      "outputs": [],
      "source": [
        "# This displays all the images with their corresponding labels. I didn't run the code so as not to upload personal mugshots to GitHub\n",
        "labeled_image_tuples = zip(test_input, test_val, y_true)\n",
        "fig, axes = plt.subplots(nrows=len(y_true), ncols=3, figsize=(10, 80))\n",
        "for i, (img1, img2, label) in enumerate(labeled_image_tuples):\n",
        "    axes[i, 0].imshow(img1)\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    axes[i, 1].imshow(img2)\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    axes[i, 2].text(0, 0.5, ['True' if label == 1.0 else 'False'],\n",
        "                    ha='left', va='center', fontsize=12)\n",
        "    axes[i, 2].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "_0iLI6saxmQo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0iLI6saxmQo",
        "outputId": "aa766fce-3d8f-4bfb-ece4-e0e16f6c2235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "siamese_model.save('siamese_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3---1rLUx9Pv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3---1rLUx9Pv",
        "outputId": "0eb48006-5336-480a-e38b-40cfaefc320d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('app/siamese_model2.h5',\n",
        "                                   custom_objects={'L1Dist': L1Dist, 'BinaryCrossentropy': tf.losses.BinaryCrossentropy})\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "Sg8aBNMfzSKs",
      "metadata": {
        "id": "Sg8aBNMfzSKs"
      },
      "source": [
        "# Real-time predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "OEGlKt66zVVO",
      "metadata": {
        "id": "OEGlKt66zVVO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 183] Cannot create a file when that file already exists: 'application_data/verification_images'\n",
            "[WinError 183] Cannot create a file when that file already exists: 'application_data/input_image'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    os.makedirs('application_data/verification_images')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "try:\n",
        "    os.makedirs('application_data/input_image')\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "31899979",
      "metadata": {},
      "outputs": [],
      "source": [
        "VERIFICATION_PATH = os.path.join('application_data', 'verification_images')\n",
        "INPUT_PATH = os.path.join('application_data', 'input_image')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "896570b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This takes 25 images from both anchor and positive examples and moves them to\n",
        "# verification directory\n",
        "verification_source_dirs = (ANC_PATH, POS_PATH)\n",
        "for directory in verification_source_dirs:\n",
        "    for index, file in enumerate(os.listdir(directory)):\n",
        "        EX_PATH = os.path.join(directory, file)\n",
        "        NEW_PATH = os.path.join(VERIFICATION_PATH, file)\n",
        "        os.replace(EX_PATH, NEW_PATH)\n",
        "        if index == 25:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c5090ff0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify(model, detection_threshold, verification_threshold):\n",
        "    results = []\n",
        "    for image in os.listdir(VERIFICATION_PATH):\n",
        "        input_img = preprocess(os.path.join(INPUT_PATH, 'input_image.jpg'))\n",
        "        validation_img = preprocess(os.path.join(VERIFICATION_PATH, image))\n",
        "\n",
        "        result = model.predict(\n",
        "            list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "        results.append(result)\n",
        "    detection = np.sum(np.array(results) > detection_threshold)\n",
        "\n",
        "    verification = detection / len(os.listdir(VERIFICATION_PATH))\n",
        "    verified = verification > verification_threshold\n",
        "\n",
        "    return results, verified\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "17d29f6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250, 200:200+250, :]\n",
        "    cv2.imshow('Verification', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0XFF == ord('v'):\n",
        "        cv2.imwrite(os.path.join(INPUT_PATH, 'input_image.jpg'), frame)\n",
        "        results, verified = verify(model, 0.5, 0.5)\n",
        "        print(verified)\n",
        "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
